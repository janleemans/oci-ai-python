{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74087996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Oracle OCI AI Services Lab using Python\n",
    "# =======================================\n",
    "\n",
    "# This tutorial will walk you through all the different OCI AI services, and use them with the Python SDK\n",
    "\n",
    "# Overview of the services we'll explore :\n",
    "# 1. AI Language Service : AIServiceLanguageClient() : for language detection, sentiment analysis and translation\n",
    "# 2. AI Vision service : AIServiceVisionClient() : for object, faces and text detection in an image\n",
    "# 3. AI Speech: AIServiceSpeechClient() : transcribe the sound of a video to a text file\n",
    "\n",
    "# We'll also be using some side services,\n",
    "# - ObjectStorageClient() : Object Storage buckets because that is the way a number of the\n",
    "#   AI services take their input, for example for sound and images input\n",
    "# - IdentityClient() to authenticate to your tenancy\n",
    "\n",
    "\n",
    "# Before you start you need to make sure you can actually connect to your tenancy from your Python environment\n",
    "# Setup config for my tenancy\n",
    "# 1. Install the Python SDK on your system: sudo yum install python36-oci-sdk    More info at https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/pythonsdk.htm\n",
    "# 2. Install OCI CLI on your system : brew update && brew install oci-cli     More info at https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm\n",
    "# 3. Ensure you can connect with the CLI to your OCI instance, your .oci.config file must. be set up correctly\n",
    "#    - Ensure you have created an api key for your account.  You should obtain a Fingerprint and a private pem key, as well as an example of the .oci/config file\n",
    "#      See https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm\n",
    "\n",
    "# - import the oci library and store the oci config file in the config variable\n",
    "# - copy the OCID of the compartment you will be using into the compart variable\n",
    "\n",
    "# Useful links to documentation on the various API's:\n",
    "# Top level API Reference doc : https://docs.oracle.com/en-us/iaas/api/\n",
    "# - Langauge : https://docs.oracle.com/en-us/iaas/api/#/en/language/20221001/\n",
    "# - Vision : https://docs.oracle.com/en-us/iaas/api/#/en/vision/20220125/\n",
    "# - Speach: https://docs.oracle.com/en-us/iaas/api/#/en/speech/20220101/\n",
    "# - Buckets: https://docs.oracle.com/en-us/iaas/api/#/en/objectstorage/20160918/\n",
    "\n",
    "\n",
    "import oci\n",
    "\n",
    "# Make sure to configure the .oci/config file as proposed during the creation of an API key for your oci user.\n",
    "config = oci.config.from_file(\"~/.oci/config\", \"DEFAULT\")\n",
    "\n",
    "# Replace the below ocid with the ocid of your compartment\n",
    "compart = \"ocid1.compartment.oc1..aaaaa… your OCID …\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e08805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Authentication\n",
    "#------------------------\n",
    "# Before attempting more complex commands, validate your SDK is working correctly\n",
    "# by displaying the regions of your tenancy, using the IdentityClient()\n",
    "\n",
    "idd = oci.identity.IdentityClient(config)\n",
    "\n",
    "regions = idd.list_regions().data\n",
    "for region in regions:\n",
    "    print(region.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List buckets and content of the buckets\n",
    "# ---------------------------------------\n",
    "# List all the buckets and the objects in each bucket that are present in the compartment you specified\n",
    "\n",
    "# Lets create a bucket to use in this lab:\n",
    "bucket_name = \"ai-lab-bucket1\"\n",
    "\n",
    "object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
    "namespace = object_storage_client.get_namespace().data\n",
    "\n",
    "\n",
    "# Loop over all the buckets to check if this bucket already exists\n",
    "buckets = object_storage_client.list_buckets(namespace, compart).data\n",
    "is_there = False\n",
    "\n",
    "for bucket in buckets:\n",
    "    print(\"Bucket name: \",bucket.name)\n",
    "    buck_name = bucket.name\n",
    "    if buck_name == bucket_name:\n",
    "        is_there = True\n",
    "    objects = object_storage_client.list_objects(namespace, buck_name).data\n",
    "    count = 1\n",
    "    for i in objects.objects:\n",
    "        print(\"Object \",count,\": \",i.name)\n",
    "        count+=1\n",
    "\n",
    "# If the bucket does not yet exist, create it\n",
    "if is_there == False:\n",
    "    create_bucket_response = object_storage_client.create_bucket(\n",
    "        namespace_name=namespace,\n",
    "        create_bucket_details=oci.object_storage.models.CreateBucketDetails(\n",
    "            name=bucket_name,\n",
    "            compartment_id=compart,\n",
    "            ))\n",
    "\n",
    "    # Get the data from response\n",
    "    print(create_bucket_response.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e46a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# AI Service : Language detection\n",
    "#--------------------------------\n",
    "\n",
    "ai_language_client = oci.ai_language.AIServiceLanguageClient(config)\n",
    "\n",
    "# French : \n",
    "#text = \"Et encore une autre langue, es-possible qu'il le comprend ?\"\n",
    "\n",
    "# Dutch:\n",
    "text = \"Een tekst in mijn moedertaal om het een beetje moeilijker te maken voor de service\"\n",
    "\n",
    "# English:\n",
    "#text = \"This should be fairly easy to detect, I'll avoid using the name of the actual language in this text\"\n",
    "\n",
    "response = ai_language_client.detect_dominant_language(\n",
    "    oci.ai_language.models.DetectLanguageSentimentsDetails(\n",
    "        text=text\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.data.languages)\n",
    "\n",
    "# You can play with the comment signs before the various languages to try different use-cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1132bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis\n",
    "\n",
    "# We can now use this same service to do sentiment analysis on a longer text : \n",
    "\n",
    "# Format the input text in the proper way so the service can interprete it\n",
    "\n",
    "# first example with some negative language\n",
    "t_doc = oci.ai_language.models.TextDocument(\n",
    "    key=\"doc1\",\n",
    "    text=\"This hotel is a bad place, I would strongly advise against going there\",\n",
    "    language_code=\"en\")\n",
    "\n",
    "s_det=oci.ai_language.models.BatchDetectLanguageSentimentsDetails(\n",
    "    documents=[t_doc], \n",
    "    compartment_id = compart)\n",
    "#print(s_det)\n",
    "\n",
    "b_rep = ai_language_client.batch_detect_language_sentiments(s_det, level=[\"ASPECT\"])\n",
    "\n",
    "print (b_rep.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second example with positive text\n",
    "my_documents = oci.ai_language.models.TextDocument(\n",
    "    key = \"doc1\",\n",
    "    text = \"\"\"OCI recently added new services to existing compliance program including SOC, HIPAA, and ISO to enable our customers to solve their \n",
    "use cases. We also released new white papers and guidance documents related to Object Storage, the Australian Prudential Regulation Authority (APRA), and the \n",
    "Central Bank of Brazil. These resources help regulated customers better understand how OCI supports their regional and industry-specific compliance \n",
    "requirements. Not only are we expanding our number of compliance offerings and regulatory alignments, we continue to add regions and services at a faster clip.\n",
    "        \"\"\",\n",
    "    language_code =  \"en\"\n",
    "    )\n",
    "\n",
    "s_det=oci.ai_language.models.BatchDetectLanguageSentimentsDetails(\n",
    "    documents=[my_documents], \n",
    "    compartment_id = compart)\n",
    "\n",
    "b_rep = ai_language_client.batch_detect_language_sentiments(s_det, level=[\"ASPECT\"])\n",
    "\n",
    "print (b_rep.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate\n",
    "\n",
    "# Translate a few sentences from English to Dutch.  Feel free to change the text or the languages\n",
    "\n",
    "ai_client = oci.ai_language.AIServiceLanguageClient(oci.config.from_file())\n",
    "\n",
    "key1 = \"doc1\"\n",
    "key2 = \"doc2\"\n",
    "text1 = \"The Indy Autonomous Challenge is the worlds first head-to-head, high speed autonomous race taking place at the Indianapolis Motor Speedway\"\n",
    "text2 = \"OCI will be the cloud engine for the artificial intelligence models that drive the MIT Driverless cars.\"\n",
    "target_language = \"nl\" #TODO specify the target language\n",
    "\n",
    "doc1 = oci.ai_language.models.TextDocument(key=key1, text=text1, language_code=\"en\")\n",
    "doc2 = oci.ai_language.models.TextDocument(key=key2, text=text2, language_code=\"en\")\n",
    "documents = [doc1, doc2]\n",
    "\n",
    "\n",
    "batch_language_translation_details = oci.ai_language.models.BatchLanguageTranslationDetails(\n",
    "    documents=documents, \n",
    "    compartment_id=compart, \n",
    "    target_language_code=target_language)\n",
    "output = ai_client.batch_language_translation (batch_language_translation_details)\n",
    "print(output.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Vision Service\n",
    "#------------------\n",
    "\n",
    "# Select a local file and upload it to the bucket we selected earlier\n",
    "\n",
    "object_storage = oci.object_storage.ObjectStorageClient(config)\n",
    "\n",
    "# Set up the file path\n",
    "#file_path = \"gg-seminar2.mp4\"\n",
    "file_path = \"aa.jpg\"\n",
    "\n",
    "# Upload the file to the bucket\n",
    "with open(file_path, \"rb\") as f:\n",
    "    put_object_response = object_storage.put_object(\n",
    "        namespace_name=namespace,\n",
    "        bucket_name = bucket_name, \n",
    "        object_name = file_path.split(\"/\")[-1], \n",
    "        put_object_body = f)\n",
    "    \n",
    "print(put_object_response.data)\n",
    "\n",
    "# You can run this command a few times with different files.  \n",
    "# Make sure to upload following files : \n",
    "# - one image file that contains some clear objects,\n",
    "# - an image file with some text\n",
    "# - an image file with people in the picture\n",
    "# - a video file with english audio\n",
    "\n",
    "# A result \"None\" means the upload succeeded !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-run the list command on the bucket to check if the new file is present:\n",
    "objects = object_storage_client.list_objects(namespace, bucket_name).data\n",
    "count = 1\n",
    "for i in objects.objects:\n",
    "    print(\"Object \",count,\": \",i.name)\n",
    "    count+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to run the actual Vision commands on the uploaded files\n",
    "\n",
    "ai_vision_client = oci.ai_vision.AIServiceVisionClient(config)\n",
    "\n",
    "namespace = object_storage_client.get_namespace().data\n",
    "\n",
    "# Send the request to service, some parameters are not required, see API\n",
    "# doc for more info\n",
    "analyze_image_response = ai_vision_client.analyze_image(\n",
    "    analyze_image_details=oci.ai_vision.models.AnalyzeImageDetails(\n",
    "        features=[\n",
    "            oci.ai_vision.models.ImageClassificationFeature(\n",
    "                feature_type=\"IMAGE_CLASSIFICATION\",\n",
    "                max_results=130)],\n",
    "        image=oci.ai_vision.models.ObjectStorageImageDetails(\n",
    "            source=\"OBJECT_STORAGE\",\n",
    "            namespace_name=namespace,\n",
    "            bucket_name=bucket_name,\n",
    "            object_name=\"aa.jpg\"),\n",
    "        compartment_id=compart)\n",
    "    )\n",
    "\n",
    "# Get the data from response\n",
    "print(analyze_image_response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the faces\n",
    "# Now use the image that has people in it ...\n",
    "analyze_image_response = ai_vision_client.analyze_image(\n",
    "    analyze_image_details=oci.ai_vision.models.AnalyzeImageDetails(\n",
    "        features=[\n",
    "            oci.ai_vision.models.ImageClassificationFeature(\n",
    "                # Set the feature type to Face Detection ...\n",
    "                feature_type=\"FACE_DETECTION\",\n",
    "                max_results=10)],\n",
    "        image=oci.ai_vision.models.ObjectStorageImageDetails(\n",
    "            source=\"OBJECT_STORAGE\",\n",
    "            namespace_name=namespace,\n",
    "            bucket_name=bucket_name,\n",
    "            object_name=\"aa.jpg\"),\n",
    "        compartment_id=compart)\n",
    "    )\n",
    "print(analyze_image_response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356879b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find text in the image\n",
    "\n",
    "# Make sure to use an uploaded image with some text in it\n",
    "analyze_image_response = ai_vision_client.analyze_image(\n",
    "    analyze_image_details=oci.ai_vision.models.AnalyzeImageDetails(\n",
    "        features=[\n",
    "            oci.ai_vision.models.ImageClassificationFeature(\n",
    "                # Set the feature to text detection\n",
    "                feature_type=\"TEXT_DETECTION\",\n",
    "                max_results=10)],\n",
    "        image=oci.ai_vision.models.ObjectStorageImageDetails(\n",
    "            source=\"OBJECT_STORAGE\",\n",
    "            namespace_name=namespace,\n",
    "            bucket_name=bucket_name,\n",
    "            object_name=\"aa.jpg\"),\n",
    "        compartment_id=compart)\n",
    "    )\n",
    "#print(analyze_image_response.data)\n",
    "for i in analyze_image_response.data.image_text.lines:\n",
    "    print (i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b30395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speach\n",
    "\n",
    "# We'll now use a sound or video file we uploaded to extract the speach as text\n",
    "ai_speech_client = oci.ai_speech.AIServiceSpeechClient(config)\n",
    "\n",
    "create_transcription_job_response = ai_speech_client.create_transcription_job(\n",
    "    create_transcription_job_details=oci.ai_speech.models.CreateTranscriptionJobDetails(\n",
    "        compartment_id=compart,\n",
    "        input_location=oci.ai_speech.models.ObjectListInlineInputLocation(\n",
    "            location_type=\"OBJECT_LIST_INLINE_INPUT_LOCATION\",\n",
    "            object_locations=[\n",
    "                oci.ai_speech.models.ObjectLocation(\n",
    "                    namespace_name=namespace,\n",
    "                    bucket_name=bucket_name,\n",
    "                    object_names=[\"gg-seminar.mp4\"])]),\n",
    "        output_location=oci.ai_speech.models.OutputLocation(\n",
    "            namespace_name=namespace,\n",
    "            bucket_name=bucket_name),\n",
    "#            prefix=\"res-\"),\n",
    "        additional_transcription_formats=[\"SRT\"],\n",
    "        display_name = \"gg-job\",\n",
    "        model_details=oci.ai_speech.models.TranscriptionModelDetails(\n",
    "            domain=\"GENERIC\",\n",
    "            language_code=\"en-GB\",\n",
    "            transcription_settings=oci.ai_speech.models.TranscriptionSettings(\n",
    "                diarization=oci.ai_speech.models.Diarization(\n",
    "                    is_diarization_enabled=False,\n",
    "                    number_of_speakers=2)))))\n",
    "\n",
    "# Get the data from response\n",
    "print(create_transcription_job_response.data)\n",
    "\n",
    "# You see the request submitted, not yet the result !\n",
    "# If all goes well, you should see a lifecycle_state\": \"ACCEPTED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b90032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the available jobs to see the status, and detect when it has finished\n",
    "\n",
    "ai_speech_client = oci.ai_speech.AIServiceSpeechClient(config)\n",
    "\n",
    "\n",
    "list_transcription_jobs_response = ai_speech_client.list_transcription_jobs(\n",
    "    compartment_id=compart,\n",
    "    display_name=\"gg-job\")\n",
    "\n",
    "# Get the data from response\n",
    "#print(list_transcription_jobs_response.data)\n",
    "\n",
    "ct=0\n",
    "for i in list_transcription_jobs_response.data.items:\n",
    "    print(\"Job no. \",ct,\", date= \", list_transcription_jobs_response.data.items[ct].time_accepted,\n",
    "         \", Status = \", list_transcription_jobs_response.data.items[ct].lifecycle_state) \n",
    "    ct+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab33ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few elements from the job to create the get_transcription_job call : \n",
    "\n",
    "\n",
    "job_id = create_transcription_job_response.data.id\n",
    "print (\"Job ID: \", job_id)\n",
    "\n",
    "out_loc = create_transcription_job_response.data.output_location.prefix\n",
    "print (\"Location: \", out_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from response\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    get_transcription_job_response = ai_speech_client.get_transcription_job(\n",
    "        transcription_job_id=job_id)\n",
    "    print(get_transcription_job_response.data.lifecycle_state, \" at \", time.ctime())\n",
    "    if get_transcription_job_response.data.lifecycle_state == \"SUCCEEDED\":\n",
    "        break\n",
    "    time.sleep(5)\n",
    "    \n",
    "\n",
    "# Get the original filename\n",
    "ori_name = get_transcription_job_response.data.input_location.object_locations[0].object_names[0]\n",
    "print(\"Original name = \",ori_name)\n",
    "\n",
    "# Compose the path to the result file:\n",
    "res_file = out_loc + namespace + \"_\" + bucket_name + \"_\" + ori_name +\".json\"\n",
    "print(\"Result filename: \", res_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize service client with default config file\n",
    "#object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
    "\n",
    "# Send the request to service, some parameters are not required, see API\n",
    "# doc for more info\n",
    "get_object_response = object_storage_client.get_object(\n",
    "    namespace_name=namespace,\n",
    "    bucket_name=bucket_name,\n",
    "    http_response_content_type = 'text/plain',\n",
    "    object_name=res_file)\n",
    "\n",
    "# Get the data from response\n",
    "print(get_object_response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc009dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint; \n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Intermediate step to dump the content of the response in a text file\n",
    "the_obj = get_object_response.data\n",
    "with open(\"my_test.txt\", 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(the_obj, outp)\n",
    "# Remark : for some reason this dump is required, otherwise I get a \"_content\"=\"FALSE\" and I only see the header, not the actual data ...\n",
    "        \n",
    "# It was a bit hard to understand the response type, \n",
    "# the below vars() command (in comment) allowed me to see what was \n",
    "# inside the actual object and discover that '_content' was the element to use !\n",
    "#pprint(vars(the_obj))\n",
    "\n",
    "# Decode the binary object to a string\n",
    "decoded_string = the_obj._content.decode(\"utf-8\")\n",
    "#print(decoded_string)\n",
    "\n",
    "# Decode the string to proper json\n",
    "json_object = json.loads(decoded_string)\n",
    "print (json_object[\"transcriptions\"][0][\"transcription\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f75a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This concludes the lab for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c7491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
